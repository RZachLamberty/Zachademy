{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.offline\n",
    "import plotly.graph_objs as go\n",
    "import requests\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "\n",
    "try:\n",
    "    import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementing CADE in `python`\n",
    "\n",
    "## introduction\n",
    "\n",
    "### sources\n",
    "\n",
    "I'm basing this off of conversations with ozan, mike, and wayne, as well as\n",
    "\n",
    "+ [this paper](https://kdl.cs.umass.edu/papers/friedland-et-al-sdm2014.pdf)\n",
    "+ [associated main page at umass](https://kdl.cs.umass.edu/display/public/Classifier-Adjusted+Density+Estimation+for+Anomaly+Detection+and+One-Class+Classification)\n",
    "+ [kenny darrell's blog post](http://darrkj.github.io/blog/2014/may102014/)\n",
    "+ [kenny darrell's R code](https://github.com/darrkj/CADE/blob/master/R/outlier.R)\n",
    "\n",
    "from mike:\n",
    "\n",
    "> You already know CADE, but let me give you my simple view of the process steps:\n",
    ">\n",
    ">   1. Limit the ABT to just the n records of interest with only the ID columns and the inputs, hiding the actual target\n",
    ">   2. Add a column, tgt_anom_ind, the intermediate target variable, and assign all rows in the ABT a value of 0\n",
    ">   3. Synthesize n additional rows (same number of rows as the real records) into the ABT, and assign tgt_anom_ind=1 to these artificial rows.  The ABT will have doubled in size.\n",
    ">   4. Build a model that predicts tgt_anom_ind accurately.  Turns out, random forest has always worked extremely well for this, so please use that.  It typically gives an ROC AUC of 0.99 or so.\n",
    ">   5. Score all the records in the ABT, adding a column of the probability that tgt_anom_ind=1, p_tgt_anom_ind which ranges from 0. to 1.0\n",
    ">   6. Remove the synthetic records from the ABT, leaving just the original columns plus the new p_tgt_anom_ind\n",
    ">   7. Graph the distribution of p_tgt_anom, and decide on a threshold value to call out anomalous records\n",
    "> \n",
    "> Now, in this use case, we see how well we did against the CoverType4_ind true target.  Just report the average value of p_tgt_anom_ind for CoverType4_ind=1 vs. against CoverType4_ind=0.  I see a 5x difference.\n",
    "> \n",
    "> The hard part is step 3 above, synthesizing n rows.  I will put that in a separate email.  I have my methods!\n",
    "> \n",
    "> Following up on step 3, the \"synthetic\" observations. (Plus, I am attaching some example data, including the metadata.)\n",
    "We get different answers (about which real observations were anomalous) depending on which method we choose--a point that will be made clear in class.\n",
    "> \n",
    "> Here are three major methods for creating synthetic records:\n",
    "> \n",
    "> + Uniform random distribution:\n",
    ">     + For continuous real features, take the observed range, then assign synthetic values randomly (uniform random distribution) within that range.\n",
    ">     + For nominal features, take the observed values and then assign synthetic values randomly equally among the nominal levels\n",
    "> + Normal random distribution:\n",
    ">     + For continuous real features, take the observed range mean and standard deviation, then assign synthetic values randomly (normal random distribution) for that distribution.  Then, you have an additional step:  cap and floor the synthetic value to be the min and max of the observed range.\n",
    ">     + For nominal features, do the same as is described in the shuffled distribution below.\n",
    "> + Shuffled distribution:\n",
    ">     + Shuffle each feature vector randomly, then put them back together into a table.  Just like target shuffling, except that we do it for each of the features separately (with different random seeds).\n",
    ">\n",
    "> The hands on exercise will use methods 1 and 2, first with all the inputs and second with the known predictive features (elevation, horizontal distance to roadways, and 9am shade).  What we will see is that method 1 produces 5x lift over random, but method 2 produces no lift when all the inputs are used and actually produces negative lift when just the predictive inputs are used.\n",
    "> \n",
    "> Lessons learned from hands-on exercise:\n",
    "> \n",
    "> + CADE with synthetic records created with Uniform distribution typically produces a predictive anomaly score.  This is borne out in the papers on this and my own experience, and in this example gives a 5x lift.\n",
    "> + CADE with other distributions may or may not be helpful.\n",
    "> + Having labeled data is EXTREMELY helpful--dramatically (an order of magnitude or more) more helpful than the \"back door\" unsupervised methods (including cluster analysis, btw).\n",
    ">\n",
    "> Said another way, this demonstrates that an outlier score (e.g., the uniform CADE score) can be related to the target of interest in the expected way, but not reliably.  We should always remember that in fraud use cases, the fraudsters do their utmost to look \"normal.\"  To the extent they are successful, unsupervised anomaly detection will not find them!  So, yes, we should always be on the lookout for anomalies, but this should be no substitute for labeled fraud pattern analysis and modeling.  Having said that, some anomaly scores (of which there are many different flavors) may well be among the many predictive features in a supervised fraud model, so unsupervised learning is a valuable tool in the fraud analyst's toolkit.\n",
    "> \n",
    "> I am anxious to see how you code this up in Python!  I am not a Python programmer but learning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data\n",
    "\n",
    "we're going to work with two datasets:\n",
    "\n",
    "1. [the forest cover dataset](http://odds.cs.stonybrook.edu/forestcovercovertype-dataset/)\n",
    "    + [uci landing page](https://archive.ics.uci.edu/ml/datasets/Covertype)\n",
    "    + [direct download via dropbox](https://www.dropbox.com/s/awx8iuzbu8dkxf1/cover.mat?dl=0), not automated\n",
    "2. a randomly generated 3d dataset\n",
    "    + automated below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forest cover\n",
    "\n",
    "first, let's download the `gz` archive to our `/tmp` director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = os.path.join(os.sep, 'tmp')\n",
    "if not os.path.isdir(tmpdir):\n",
    "    os.makedirs(tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz'\n",
    "fgzdownload = os.path.join(os.sep, 'tmp', os.path.basename(url))\n",
    "resp = requests.get(url)\n",
    "with open(fgzdownload, 'wb') as f:\n",
    "    f.write(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unzip that bad boy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcover = os.path.splitext(fgzdownload)[0]\n",
    "\n",
    "with gzip.open(fgzdownload, 'rb') as fin, open(fcover, 'wb') as fout:\n",
    "    fout.write(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcover = pd.read_csv(fcover, header=None)\n",
    "dfcover.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add column names (going off info [here](https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    'Elevation',\n",
    "    'Aspect',\n",
    "    'Slope',\n",
    "    'Horizontal_Distance_To_Hydrology',\n",
    "    'Vertical_Distance_To_Hydrology',\n",
    "    'Horizontal_Distance_To_Roadways',\n",
    "    'Hillshade_9am',\n",
    "    'Hillshade_Noon',\n",
    "    'Hillshade_3pm',\n",
    "    'Horizontal_Distance_To_Fire_Points',\n",
    "]\n",
    "attributes = [_.lower() for _ in attributes]\n",
    "wildernessareas = ['wilderness_area_{}'.format(i) for i in range(4)]\n",
    "soiltypes = ['soil_type_{}'.format(i) for i in range(40)]\n",
    "coverpredictors = attributes + wildernessareas + soiltypes\n",
    "colnames = coverpredictors + ['covertype']\n",
    "\n",
    "dfcover.columns = colnames\n",
    "dfcover.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "later on it will matter that some of these are continuous and others are categorical (the binary ones). let's encode that as the dtype (categorical as it is more generic than boolean):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = wildernessareas + soiltypes + ['covertype']\n",
    "for column in categoricals:\n",
    "    dfcover.loc[:, column] = dfcover[column].astype('category')\n",
    "\n",
    "dfcover.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random 3d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrand, yrand = sklearn.datasets.make_blobs(\n",
    "    n_samples=1000, n_features=3, centers=[[0, 0, 0]], random_state=1337\n",
    ")\n",
    "dfrand = pd.DataFrame(xrand, columns=['x', 'y', 'z'])\n",
    "dfrand.loc[:, 'is_corner'] = 0\n",
    "dfrand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this dataset already has naturally occurring outliers, but let's also manually add 8 relatively extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcorners = pd.DataFrame(\n",
    "    list(itertools.product([-2, 2], repeat=3)), \n",
    "    columns=['x', 'y', 'z']\n",
    ")\n",
    "dfcorners.loc[:, 'is_corner'] = 1\n",
    "dfcorners.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrand = pd.concat([dfrand, dfcorners]).reset_index(drop=True)\n",
    "dfrand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrand.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    go.Scatter3d(\n",
    "        x=dfrand.x,\n",
    "        y=dfrand.y,\n",
    "        z=dfrand.z,\n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'opacity': 0.8, \n",
    "            'color': dfrand.is_corner,\n",
    "            'colorscale': 'Portland'\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(width=800, height=800)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**one important note**: our goal in creating these corner elements *isn't* to distinguish the \"fake\" data from the \"real\" data, but rather to have some items we know ahead of time *should* be observerd, by CADE, to be anomalies.\n",
    "\n",
    "even in the regular dataset there were already anomalous records -- you can see that visually -- but we are stacking the example with some simple cases in addition to the random ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementing CADE\n",
    "\n",
    "### creating synthetic records\n",
    "\n",
    "as mike outlined (see the above), there are three ways to generate synthetic records:\n",
    "\n",
    "+ uniform\n",
    "+ normal\n",
    "+ shuffled\n",
    "\n",
    "let's implement them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOMINAL_DTYPES = ['category']\n",
    "\n",
    "def synthetic_generator_uniform(df):\n",
    "    def synth(feature):\n",
    "        if feature.dtype.name in NOMINAL_DTYPES:\n",
    "            synth = sklearn.utils.resample(\n",
    "                feature, n_samples=feature.shape[0]\n",
    "            ).values\n",
    "        else:\n",
    "            synth = np.random.uniform(\n",
    "                1.25 * feature.min(), 1.25 * feature.max(), feature.shape[0]\n",
    "            )\n",
    "        return synth\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        colname: synth(feature) for (colname, feature) in df.iteritems()\n",
    "    })[df.columns]\n",
    "\n",
    "\n",
    "def synthetic_generator_normal(df):\n",
    "    def synth(feature):\n",
    "        if feature.dtype.name in NOMINAL_DTYPES:\n",
    "            synth = sklearn.utils.shuffle(feature).values\n",
    "        else:\n",
    "            synth = np.random.normal(\n",
    "                feature.mean(), feature.max(), feature.shape[0]\n",
    "            )\n",
    "        return synth\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        colname: synth(feature) for (colname, feature) in df.iteritems()\n",
    "    })[df.columns]\n",
    "\n",
    "\n",
    "def synthetic_generator_shuffled(df):\n",
    "    return pd.DataFrame({\n",
    "        colname: sklearn.utils.shuffle(feature).values \n",
    "        for (colname, feature) in df.iteritems()\n",
    "    })[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = synthetic_generator_uniform(dfcover)\n",
    "synth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random distribution POC\n",
    "\n",
    "let's take the random 3d dataset and walk through the algo one step at a time, following mike's 7-step outline\n",
    "\n",
    "### abt with no target\n",
    "\n",
    "Limit the ABT to just the n records of interest with only the ID columns and the inputs, hiding the actual target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrand.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add an anomaly metatarget \n",
    "\n",
    "Add a column, tgt_anom_ind, the intermediate target variable, and assign all rows in the ABT a value of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrand.loc[:, 'is_real'] = 1\n",
    "dfrand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create duplicate synthetic dataset\n",
    "\n",
    "Synthesize n additional rows (same number of rows as the real records) into the ABT, and assign tgt_anom_ind=1 to these artificial rows.  The ABT will have doubled in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randpredictors = ['x', 'y', 'z']\n",
    "dfrandsynth = synthetic_generator_uniform(dfrand[randpredictors])\n",
    "dfrandsynth.loc[:, 'is_real'] = 0\n",
    "dfrandsynth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfboth = pd.concat([dfrand, dfrandsynth]).reset_index(drop=True)\n",
    "dfboth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfboth.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    go.Scatter3d(\n",
    "        x=dftemp.x, y=dftemp.y, z=dftemp.z,\n",
    "        mode='markers',\n",
    "        name=name,\n",
    "        marker={'opacity': opacity}\n",
    "    )\n",
    "    for (name, dftemp, opacity) in [\n",
    "        ['real regular', dfboth[dfboth.is_corner == 0], 0.8],\n",
    "        ['real corner', dfboth[dfboth.is_corner == 1], 0.8],\n",
    "        ['syntehtic', dfboth[dfboth.is_real == 0], 0.4],\n",
    "    ]\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict metatarget\n",
    "\n",
    "Build a model that predicts tgt_anom_ind accurately.  Turns out, random forest has always worked extremely well for this, so please use that.  It typically gives an ROC AUC of 0.99 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfboth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfboth[['x', 'y', 'z']]\n",
    "y = dfboth.is_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not sure if I should be training with a validation set or not. it feels, intuitively, that it defeats the point. we train it excessively well because the predictor score matters more than the generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = sklearn.ensemble.RandomForestClassifier(n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score abt\n",
    "\n",
    "Score all the records in the ABT, adding a column of the probability that tgt_anom_ind=1, p_tgt_anom_ind which ranges from 0. to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfboth.loc[:, 'predicted_probability_is_real'] = rfc.predict_proba(x)[:, 1]\n",
    "dfboth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y_true=dfboth.is_real, y_score=dfboth.predicted_probability_is_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at only real records\n",
    "\n",
    "Remove the synthetic records from the ABT, leaving just the original columns plus the new p_tgt_anom_ind\n",
    "Graph the distribution of p_tgt_anom, and decide on a threshold value to call out anomalous records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfboth[dfboth.is_real == 1].sort_values(by='predicted_probability_is_real').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfboth[dfboth.is_corner == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdh = dfboth[dfboth.is_real == 1].sort_values(\n",
    "    by='predicted_probability_is_real'\n",
    ")\n",
    "\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=list(range(dfdh.shape[0])),\n",
    "        y=dfdh.predicted_probability_is_real,\n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'opacity': 0.8, \n",
    "            'color': dfdh.is_corner,\n",
    "            'size': np.where(dfdh.is_corner == 1, 15, 5),\n",
    "            'colorscale': 'Portland',\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the plot above, the items on the lower left are the ones which were most confusing to our classifier -- that is, they were harder to distinguish from that uniformally distributed cloud of points than the bulk of points near the origin.\n",
    "\n",
    "let's take, as our cutoff, the value of the least-confusing corner, and declare any record with a predicted probability value below that cutoff to be an anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = dfboth[dfboth.is_corner == 1].predicted_probability_is_real.max()\n",
    "\n",
    "dfboth.loc[(dfboth.is_real == 1) & (dfboth.predicted_probability_is_real <= cutoff), 'is_anomaly'] = 1\n",
    "dfboth.is_anomaly.fillna(0, inplace=True)\n",
    "dfboth[dfboth.is_anomaly == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many anomalies is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfboth.is_anomaly.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now, to visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot = dfboth[dfboth.is_real == 1]\n",
    "data = [\n",
    "    go.Scatter3d(\n",
    "        x=dfplot.x,\n",
    "        y=dfplot.y,\n",
    "        z=dfplot.z,\n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'opacity': 0.8, \n",
    "            'color': dfplot.is_anomaly,\n",
    "            'colorscale': 'Portland'\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(width=800, height=800)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not too bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a general framework\n",
    "\n",
    "let's pick an interface and implement the above as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cade(dfreal, predictorcols, synthfunc=synthetic_generator_uniform,\n",
    "         model=None, plotprobs=True, inplace=True):\n",
    "    \"\"\"perform the CADE outlier detection algorithm\n",
    "    \n",
    "    args:\n",
    "        dfreal (pandas DataFrame): a dataframe of real records to which we wish \n",
    "            to apply the CADE algorithm\n",
    "        predictorcols (list): a list of string column names of the predictor \n",
    "            columns in `dfreal`\n",
    "        synthfunc (func): a function which can take a pandas dataframe and \n",
    "            generate synthetic data. the output will be concatenated with the\n",
    "            values in `dfreal` and used as the training set for `model`\n",
    "        model (None or scikit learn model): an object which has a `fit` and\n",
    "            `predict_proba` method (*a la* a scikit learn model). this model is\n",
    "            used by the CADE algorithm when it predicts whether a record is real \n",
    "            or synthetic. if no model is passed, we will use a 1000-tree random\n",
    "            forest by default\n",
    "        plotprobs (bool): whether or not to plot the probabilities a given \n",
    "            record is real or synthetic (as predicted by `model`)\n",
    "        inplace (bool): whether or not to update the passed `dfreal` inplace as \n",
    "            we create real and synthetic records (will change the shape of \n",
    "            `dfreal`)\n",
    "    \n",
    "    returns:\n",
    "        dfboth (pandas DataFrame): a dataframe which contains the original \n",
    "            `dfreal` records as well as synthetically generated records \n",
    "        rocauc (float): the ROC AUC of the CADE prediction\n",
    "    \n",
    "    raises:\n",
    "        ValueError\n",
    "        \n",
    "    \"\"\"\n",
    "    # build synth dataset\n",
    "    print('building synthetic records')\n",
    "    df = dfreal if inplace else dfreal.copy()\n",
    "    df.loc[:, 'is_real'] = 1\n",
    "\n",
    "    dfsynth = synthetic_generator_uniform(df[predictorcols])\n",
    "    dfsynth.loc[:, 'is_real'] = 0\n",
    "\n",
    "    dfboth = pd.concat([df, dfsynth]).reset_index(drop=True)\n",
    "\n",
    "    # get a target and predictor array and fit the user-provided model\n",
    "    print('training a model on real and synthetic data')\n",
    "    x = dfboth[predictorcols]\n",
    "    y = dfboth.is_real\n",
    "\n",
    "    if model is None:\n",
    "        model =  sklearn.ensemble.RandomForestClassifier(\n",
    "            n_estimators=1000, n_jobs=-1\n",
    "        )\n",
    "    model.fit(x, y)\n",
    "\n",
    "    # add predicted probability of being real to our real + synthetic dataset\n",
    "    dfboth.loc[:, 'predicted_prob_is_real'] = model.predict_proba(x)[:, 1]\n",
    "\n",
    "    rocauc = sklearn.metrics.roc_auc_score(\n",
    "        y_true=dfboth.is_real,\n",
    "        y_score=dfboth.predicted_prob_is_real\n",
    "    )\n",
    "    \n",
    "    # visualize the predicted probabilities if the user requests it\n",
    "    if plotprobs:\n",
    "        print('generating predicted probability plot')\n",
    "        \n",
    "        if dfboth.shape[0] > 10000:\n",
    "            # switch to a box and whiskers version\n",
    "            data = [\n",
    "                go.Box(\n",
    "                    y=chunk.predicted_prob_is_real,\n",
    "                    name='is_real = {}'.format(isrealval),\n",
    "                    boxpoints='outliers'\n",
    "                )\n",
    "                for (isrealval, chunk) in dfboth.groupby('is_real')\n",
    "            ]\n",
    "\n",
    "            layout = go.Layout(\n",
    "                title=\"predicted probabilities for real and synthetic records\",\n",
    "                showlegend=True\n",
    "            )\n",
    "        else:\n",
    "            # good ol' devil's horn plot\n",
    "            dfboth = dfboth.sort_values(by='predicted_prob_is_real')\n",
    "\n",
    "            data = [\n",
    "                go.Scatter(\n",
    "                    x=list(range(dfboth.shape[0])),\n",
    "                    y=dfboth.predicted_prob_is_real,\n",
    "                    mode='markers',\n",
    "                    marker={\n",
    "                        'opacity': 0.8, \n",
    "                        'color': dfboth.is_real,\n",
    "                        'colorscale': 'Portland'\n",
    "                    }\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            layout = go.Layout(\n",
    "                title=\"predicted probability for real and synthetic records\",\n",
    "                xaxis={'title': 'predicted probability sort order index'},\n",
    "                yaxis={'title': 'predicted probability'},\n",
    "                showlegend=True\n",
    "            )\n",
    "        \n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        plotly.offline.iplot(fig)\n",
    "\n",
    "    return dfboth, rocauc\n",
    "\n",
    "\n",
    "def declare_anomaly(dfreal, cutoff=None, numanom=None, anomalycol='is_anomaly',\n",
    "                    cadepredictioncol='predicted_prob_is_real'):\n",
    "    \"\"\"add a column to `dfreal` indicating whether or not a record is considered \n",
    "    to be an anomaly. \n",
    "    \n",
    "    given a dataframe of *only real* records (i.e. synthetics already dropped),\n",
    "    we add a column `anomalycol` that is a 1 if a record is an anomaly based on\n",
    "    a CADE predicted probability column `cadepredictioncol`.\n",
    "    \n",
    "    one (and only one) of `cutoff` and `numanom` can be provided\n",
    "    \n",
    "    args:\n",
    "        dfreal (pandas DataFrame): dataframe of *only real records*. you *must* \n",
    "            have dropped synthetic records from `dfreal` in order for this \n",
    "            function to make sense\n",
    "        cutoff (None or float): the numerical value of the cutoff predicted \n",
    "            probability (every record with a predicted probability less than \n",
    "            this value is declared an anomaly)\n",
    "        numanom (None or int): integer number of records you wish to declare \n",
    "            annomalous\n",
    "        anomalycol (str): column name of output anomaly indicator column\n",
    "        cadepredictioncol (str): existing column name of predicted probability \n",
    "            values\n",
    "            \n",
    "    returns:\n",
    "        dfreal (pandas DataFrame): the dataframe with an additional column \n",
    "            indicating annomalous records\n",
    "    \n",
    "    raises:\n",
    "        ValueError\n",
    "    \"\"\"\n",
    "    if (cutoff is None) == (numanom is None):\n",
    "        raise ValueError(\n",
    "            \"you must provide one and only one of `cutoff` or `numanom`\"\n",
    "        )\n",
    "    \n",
    "    dfreal = dfreal.sort_values(by=cadepredictioncol, ascending=True)\n",
    "    cutoff = cutoff or dfreal.iloc[int(numanom + 1), :][cadepredictioncol]\n",
    "    \n",
    "    dfreal.loc[dfreal[cadepredictioncol] < cutoff, anomalycol] = 1\n",
    "    dfreal.is_anomaly.fillna(0, inplace=True)\n",
    "    \n",
    "    return dfreal\n",
    "\n",
    "\n",
    "def visualize_binary_groups(dfreal, groupcol='is_anomaly', plotcols=['x', 'y', 'z']):\n",
    "    \"\"\"visualize records as anomalies or not anomalies\n",
    "    \n",
    "    args:\n",
    "        dfreal (pandas DataFrame): dataframe of *only real records*. you *must* \n",
    "            have dropped synthetic records from `dfreal` in order for this \n",
    "            function to make sense\n",
    "        groupcol (str): column name of distinguishing indicator column (will be \n",
    "            used to set color of scatter points)\n",
    "        plotcols (list): list of either two or three columns in the provided \n",
    "            dataset `dfreal` we should visualize. this will create a 2d or 3d\n",
    "            plot depending on what is passed\n",
    "        \n",
    "    returns:\n",
    "        None\n",
    "        \n",
    "    raises:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    coords = {k: dfreal[col] for (k, col) in zip('xyz', plotcols)}\n",
    "    if len(plotcols) == 2:\n",
    "        plotobj = go.Scatter\n",
    "    elif len(plotcols) == 3:\n",
    "        plotobj = go.Scatter3d\n",
    "    else:\n",
    "        raise ValueError('we can only visualize 2 or 3 columns at a time')\n",
    "    \n",
    "    data = [\n",
    "        plotobj(\n",
    "            mode='markers',\n",
    "            marker={\n",
    "                'opacity': 0.8, \n",
    "                'color': dfreal[groupcol],\n",
    "                'colorscale': 'Portland'\n",
    "            },\n",
    "            **coords\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        height=800,\n",
    "        width=800,\n",
    "        title=\"records colored by feature '{}'\".format(groupcol)\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    plotly.offline.iplot(fig)\n",
    "    \n",
    "    \n",
    "def example_rand_with_corners(n_samples=1000, n_features=3, random_state=1337,\n",
    "                             colnames=['x', 'y', 'z']):\n",
    "    \"\"\"build our example randomly generated dataset with anomalous corner points\n",
    "    \n",
    "    args:\n",
    "        n_samples (int): number of random records to generate\n",
    "        n_features (int): number of columns\n",
    "        random_state (int): RNG seed number\n",
    "        colnames (list): list of column names for output dataset (must have \n",
    "            `n_features` elements)\n",
    "            \n",
    "    returns:\n",
    "        dfrand (pandas DataFrame): dataframe of random normally distributed \n",
    "            records in `n_features` dimensions\n",
    "            \n",
    "    raises:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    # make regular random values\n",
    "    xrand, yrand = sklearn.datasets.make_blobs(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        centers=[[0 for i in range(n_features)]],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    dfrand = pd.DataFrame(xrand, columns=colnames)\n",
    "    dfrand.loc[:, 'is_corner'] = 0\n",
    "\n",
    "    # make \"corner\" values\n",
    "    dfcorners = pd.DataFrame(\n",
    "        list(itertools.product([-2, 2], repeat=n_features)), \n",
    "        columns=colnames\n",
    "    )\n",
    "    dfcorners.loc[:, 'is_corner'] = 1\n",
    "    \n",
    "    dfrand = pd.concat([dfrand, dfcorners]).reset_index(drop=True)\n",
    "    return dfrand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can reproduce all of the above with the following function calls:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrand = example_rand_with_corners()\n",
    "\n",
    "dfboth, rocauc = cade(\n",
    "    dfreal=dfrand,\n",
    "    predictorcols=['x', 'y', 'z']\n",
    ")\n",
    "\n",
    "print('our CADE model had a ROC AUC of {}'.format(rocauc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreal = dfboth[dfboth.is_real == 1].copy()\n",
    "dfreal = declare_anomaly(\n",
    "    dfreal=dfreal,\n",
    "    cutoff=None,\n",
    "    numanom=100,\n",
    ")\n",
    "dfboth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_binary_groups(\n",
    "    dfreal,\n",
    "    groupcol='is_anomaly', \n",
    "    plotcols=['x', 'y', 'z']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying our framework to the forest cover data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrand = example_rand_with_corners()\n",
    "\n",
    "# will use a smaller random forest for time constraints\n",
    "rfc = sklearn.ensemble.RandomForestClassifier(n_estimators=3, n_jobs=-1)\n",
    "dfboth, rocauc = cade(\n",
    "    dfreal=dfcover,\n",
    "    predictorcols=coverpredictors,\n",
    "    model=rfc\n",
    ")\n",
    "\n",
    "print('our CADE model had a ROC AUC of {}'.format(rocauc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreal = dfboth[dfboth.is_real == 1].copy()\n",
    "dfreal = declare_anomaly(\n",
    "    dfreal=dfreal,\n",
    "    cutoff=None,\n",
    "    numanom=100,\n",
    ")\n",
    "dfreal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreal[dfreal.is_anomaly == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
