{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph diffusion\n",
    "\n",
    "what follows is a walkthrough of different graph diffusion and labelling algorithms, largely based on my review of [this paper](https://arxiv.org/abs/1703.02618)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "sns.set()\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating a network for doing label propagation\n",
    "\n",
    "let's create a basic network with $N$ nodes, $L$ possible labels, and some number $n_\\ell < N$ of those $N$ nodes being labelled. our goal is to predict the other label values in a semi-supervised way.\n",
    "\n",
    "we will actually use the citeseer knowledge graph dataset as was done in the paper listed above. fortunately that's available for download as part of the GCN package [here](https://github.com/tkipf/gcn)\n",
    "\n",
    "go clone that directory somewhere and then add it to your path to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/zach.lamberty/code/gcn/gcn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = utils.load_data('citeseer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return to the place we saw in `pwd` up above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/zach.lamberty/personal/notebooks/Zachademy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quick summary of what we just downloaded:\n",
    "\n",
    "+ `adj`: node adjacency matrix\n",
    "+ `features`: the predictor dataset x (contains train and test, labelled and unlabelled)\n",
    "+ `y_{train,val,test}`: labels for training, validation, and test (all have the same shape, but the section that is filled in changes from one to the next\n",
    "+ `{train,val,test}_mask`: mask indexer for training, validatino, and test (used to subset features to the desired subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3)\n",
    "ax0.imshow(y_train, aspect='auto')\n",
    "ax1.imshow(y_val, aspect='auto')\n",
    "ax2.imshow(y_test, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_start = int(train_mask.sum() + val_mask.sum())\n",
    "unlab_stop = test_mask.argmax()\n",
    "unlab_mask = np.zeros(y_train.shape[0])\n",
    "unlab_mask[range(unlab_start, unlab_stop)] = 1\n",
    "unlab_mask = np.array(unlab_mask, dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mask = train_mask + val_mask + unlab_mask + test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(adj.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the paper they make reference to soft label data set $y_{ij}$ and affinity matrix $W$; let's build / alias those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train + y_test + y_val\n",
    "\n",
    "plt.imshow(y, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my own view: let's create a dataframe with `node_index`, `is_seed`, and `label` values as described in the docstring of the algorithm functions defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'node_index': list(range(y.shape[0])),\n",
    "    'is_seed': train_mask,\n",
    "})\n",
    "\n",
    "df0.loc[train_mask, 'label'] = y_train[train_mask, :].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = df0.label.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algo 1: label propagation\n",
    "\n",
    "basically we do a simple average of all labels among neighboring nodes and label all nodes with their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_label_prop(df_labels, adj=adj):\n",
    "    D = np.diag(np.ravel(adj.sum(axis=0)))\n",
    "    D_inv = np.diag(1 / np.ravel(adj.sum(axis=0)))\n",
    "\n",
    "    # y_lp for the known labeled cases should acutally be pm 1, not 0 and 1, per the\n",
    "    # paper's instructions.\n",
    "    df_y = df_labels.copy()\n",
    "    df_y.loc[:, 'count_val'] = 1\n",
    "    df_y = df_y.pivot(\n",
    "        index='node_index',\n",
    "        columns='label',\n",
    "        values='count_val'\n",
    "    )\n",
    "    df_y.drop(columns=np.nan, inplace=True)\n",
    "    df_y.fillna(0, inplace=True)\n",
    "\n",
    "    # for the seeds nodes, we want this df to have -1 for known negatives and +1 for\n",
    "    # known positives\n",
    "    df_y.loc[df_labels.is_seed, :] = df_y.loc[df_labels.is_seed, :] * 2 - 1\n",
    "    df_y.loc[:, 'iteration'] = 0\n",
    "    \n",
    "    df_y = df_y.set_index('iteration', append=True)\n",
    "    \n",
    "    return D_inv, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prop(df_labels, n=50, adj=adj, return_details=False):\n",
    "    \"\"\"simple spectral diffusion measure\n",
    "    \n",
    "    args:\n",
    "        df_labels (pd.DataFrame): a dataframe which contains three features:\n",
    "            `node_index`, a unique identifier for each node; `is_seed`, a \n",
    "            boolean indicating whether or not that particular node should be\n",
    "            considered a seed for this run of the algorithm, and `label`, an\n",
    "            integer value indicating which label that node has (should only be\n",
    "            set for seed nodes, but this is not enforced)\n",
    "        n (int): number of iterations to take\n",
    "        adj (np.NdArray): adjacency matrix of the graph\n",
    "        return_details (bool): whether or not to include the history of label \n",
    "            prediction values\n",
    "    \n",
    "    returns:\n",
    "        pd.DataFrame: an augmented form of the input which provides predictions\n",
    "            for the unlabelled non-seed nodes as well as in-class ordering for\n",
    "            the confidence level of that prediction\n",
    "        pd.DataFrame (optional): prediction history of values over the number of\n",
    "            iterations (only returned if `return_details = True`)\n",
    "    \n",
    "    raises:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    D_inv, df_y = _init_label_prop(df_labels, adj)\n",
    "    \n",
    "    idx = pd.IndexSlice\n",
    "    \n",
    "    for i in tqdm.tnrange(1, n + 1, leave=False):\n",
    "        # grab previous generation's y vals\n",
    "        y_prev = df_y.loc[idx[:, i - 1], :]\n",
    "\n",
    "        # diffuse the previous values with W and average\n",
    "        y_new = D_inv @ adj @ y_prev\n",
    "        \n",
    "        # override the propagated labels with the true labels\n",
    "        y_new[df_labels.is_seed] = y_prev.values[df_labels.is_seed]\n",
    "\n",
    "        df_y_new = pd.DataFrame(data=y_new)\n",
    "        df_y_new.index.name = 'node_index'\n",
    "        df_y_new.loc[:, 'iteration'] = i\n",
    "        df_y_new.set_index('iteration', append=True, inplace=True)\n",
    "\n",
    "        # concatenate the two\n",
    "        df_y = pd.concat([df_y, df_y_new], ignore_index=False)\n",
    "    \n",
    "    # calculate predicitons with margins for non-seed nodes\n",
    "    # get the last iteration\n",
    "    max_iter = df_y.index.get_level_values(-1).max()\n",
    "    df_y_final = df_y.loc[idx[:, max_iter], :]\n",
    "    df_y_final.index = df_y_final.index.droplevel(level='iteration')\n",
    "\n",
    "    # subset down to *predictions* (ignore all-0s)\n",
    "    df_y_final = df_y_final[df_y_final.max(axis=1) != 0]\n",
    "\n",
    "    # pick out the final label value for each\n",
    "    df_pred = pd.DataFrame(\n",
    "        data={\n",
    "            'label': df_y_final.idxmax(axis=1),\n",
    "            'val': df_y_final.max(axis=1),\n",
    "        },\n",
    "        index=df_y_final.index\n",
    "    )\n",
    "\n",
    "    # join in the original is_seed values to calculate prediction ranking in-class\n",
    "    df_pred = df_pred.join(\n",
    "        df_labels.set_index('node_index').is_seed, \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # in-class ranking calculation\n",
    "    df_pred = df_pred.join(\n",
    "        df_pred.groupby(['is_seed', 'label']) \\\n",
    "            .rank(ascending=False, method='min') \\\n",
    "            .rename(columns={'val': 'in_class_rank'}),\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    if return_details:\n",
    "        return df_pred, df_y.sort_index()\n",
    "    else:\n",
    "        return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred, df_y_hist = label_prop(df_labels=df0, return_details=True, n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=df_y_hist.loc[3324].index,\n",
    "        y=df_y_hist.loc[idx[3324, :], l],\n",
    "        name=l\n",
    "    )\n",
    "    for l in df_y_hist.columns\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=df_y_hist.loc[3311].index,\n",
    "        y=df_y_hist.loc[idx[3311, :], l],\n",
    "        name=l\n",
    "    )\n",
    "    for l in df_y_hist.columns\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=df_y_hist.loc[703].index,\n",
    "        y=df_y_hist.loc[idx[703, :], l],\n",
    "        name=l\n",
    "    )\n",
    "    for l in df_y_hist.columns\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how did this do against validation and training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfval = pd.DataFrame(\n",
    "    {'true_label': y_val.argmax(axis=1)},\n",
    "    index=range(y_val.shape[0]),\n",
    ")\n",
    "dfval.index.name = 'node_index'\n",
    "dfval = dfval[val_mask]\n",
    "\n",
    "dftest = pd.DataFrame(\n",
    "    {'true_label': y_test.argmax(axis=1)},\n",
    "    index=range(y_test.shape[0]),\n",
    ")\n",
    "dftest.index.name = 'node_index'\n",
    "dftest = dftest[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_evaluation(df_pred):\n",
    "    z = df_pred.join(\n",
    "        pd.concat([dfval, dftest]), how='left'\n",
    "    )\n",
    "\n",
    "    df_y_comparable = z[z.true_label.notna()]\n",
    "    accuracy = (df_y_comparable.label == df_y_comparable.true_label).mean()\n",
    "    df_y_crosstab = pd.crosstab(\n",
    "        index=df_y_comparable.label,\n",
    "        columns=df_y_comparable.true_label\n",
    "    )\n",
    "\n",
    "    return accuracy, df_y_comparable, df_y_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, df_y_comparable, df_y_crosstab = prediction_evaluation(df_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[\n",
    "    go.Heatmap(\n",
    "        x=df_y_crosstab.index,\n",
    "        y=df_y_crosstab.columns,\n",
    "        z=df_y_crosstab.values,\n",
    "        colorscale='Reds',\n",
    "    )\n",
    "]\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algo 2: normalized laplacian lp\n",
    "\n",
    "similar to a page rank, similar to the above with a hyperparameter $\\alpha$ and does updates\n",
    "\n",
    "$$\n",
    "Y^{(\\infty)} = \\alpha \\left(\\mathbb{1} - (1 - \\alpha)A\\right)^{-1} Y^{(0)}\n",
    "$$\n",
    "\n",
    "this is a random diffusion walk with an additional probabilty $\\alpha$ of not taking a step at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_norm_laplacian_lp(df_labels, adj=adj):\n",
    "    D = np.diag(np.ravel(adj.sum(axis=0)))\n",
    "    D_negsqrt = np.diag(np.ravel(adj.sum(axis=0)) ** -.5)\n",
    "    A = D_negsqrt @ adj @ D_negsqrt\n",
    "\n",
    "    # y_lp for the known labeled cases should acutally be pm 1, not 0 and 1, per\n",
    "    # the paper's instructions.\n",
    "    df_y = df_labels.copy()\n",
    "    df_y.loc[:, 'count_val'] = 1\n",
    "    df_y = df_y.pivot(\n",
    "        index='node_index',\n",
    "        columns='label',\n",
    "        values='count_val'\n",
    "    )\n",
    "    df_y.drop(columns=np.nan, inplace=True)\n",
    "    df_y.fillna(0, inplace=True)\n",
    "\n",
    "    # for the seeds nodes, we want this df to have -1 for known negatives and +1 for\n",
    "    # known positives\n",
    "    df_y.loc[df_labels.is_seed, :] = df_y.loc[df_labels.is_seed, :] * 2 - 1\n",
    "    df_y.loc[:, 'iteration'] = 0\n",
    "    \n",
    "    df_y = df_y.set_index('iteration', append=True)\n",
    "    \n",
    "    return A, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_laplacian_lp(df_labels, n=150, alpha=0.1, adj=adj, return_details=False):\n",
    "    \"\"\"simple spectral diffusion measure\n",
    "    \n",
    "    args:\n",
    "        df_labels (pd.DataFrame): a dataframe which contains three features:\n",
    "            `node_index`, a unique identifier for each node; `is_seed`, a \n",
    "            boolean indicating whether or not that particular node should be\n",
    "            considered a seed for this run of the algorithm, and `label`, an\n",
    "            integer value indicating which label that node has (should only be\n",
    "            set for seed nodes, but this is not enforced)\n",
    "        n (int): number of iterations to take (default: 150)\n",
    "        alpha (float): hyperparameter scaling the probability of our diffusion\n",
    "            walker returning to the first generation's label value\n",
    "            (default: 0.1)\n",
    "        adj (np.NdArray): adjacency matrix of the graph\n",
    "        return_details (bool): whether or not to include the history of label \n",
    "            prediction values (default: False)\n",
    "    \n",
    "    returns:\n",
    "        pd.DataFrame: an augmented form of the input which provides predictions\n",
    "            for the unlabelled non-seed nodes as well as in-class ordering for\n",
    "            the confidence level of that prediction\n",
    "        pd.DataFrame (optional): prediction history of values over the number of\n",
    "            iterations (only returned if `return_details = True`)\n",
    "    \n",
    "    raises:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    A, df_y = _init_norm_laplacian_lp(df_labels, adj)\n",
    "    \n",
    "    idx = pd.IndexSlice\n",
    "    \n",
    "    for i in tqdm.tnrange(1, n + 1, leave=True):\n",
    "        # grab first and previous generation's y vals\n",
    "        y_0 = df_y.loc[idx[:, 0], :]\n",
    "        y_prev = df_y.loc[idx[:, i - 1], :]\n",
    "\n",
    "        # diffuse the previous values with A and average\n",
    "        y_new = (1 - alpha) * A @ y_prev + alpha * y_0\n",
    "        \n",
    "        # index fucks with things\n",
    "        y_new.index = y_new.index.droplevel(level='iteration')\n",
    "\n",
    "        # override the propagated labels with the true labels\n",
    "        y_new[df_labels.is_seed] = y_prev.values[df_labels.is_seed]\n",
    "\n",
    "        # build the df\n",
    "        df_y_new = pd.DataFrame(data=y_new)\n",
    "        df_y_new.index.name = 'node_index'\n",
    "        df_y_new.loc[:, 'iteration'] = i\n",
    "        df_y_new.set_index('iteration', append=True, inplace=True)\n",
    "\n",
    "        # concatenate the two\n",
    "        df_y = pd.concat([df_y, df_y_new], ignore_index=False)\n",
    "    \n",
    "    # calculate predicitons with margins for non-seed nodes\n",
    "    # get the last iteration\n",
    "    max_iter = df_y.index.get_level_values(-1).max()\n",
    "    df_y_final = df_y.loc[idx[:, max_iter], :]\n",
    "    df_y_final.index = df_y_final.index.droplevel(level='iteration')\n",
    "\n",
    "    # subset down to *predictions* (ignore all-0s)\n",
    "    df_y_final = df_y_final[df_y_final.max(axis=1) != 0]\n",
    "\n",
    "    # pick out the final label value for each\n",
    "    df_pred = pd.DataFrame(\n",
    "        data={\n",
    "            'label': df_y_final.idxmax(axis=1),\n",
    "            'val': df_y_final.max(axis=1),\n",
    "        },\n",
    "        index=df_y_final.index\n",
    "    )\n",
    "\n",
    "    # join in the original is_seed values to calculate prediction ranking in-class\n",
    "    df_pred = df_pred.join(\n",
    "        df_labels.set_index('node_index').is_seed, \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # in-class ranking calculation\n",
    "    df_pred = df_pred.join(\n",
    "        df_pred.groupby(['is_seed', 'label']) \\\n",
    "            .rank(ascending=False, method='min') \\\n",
    "            .rename(columns={'val': 'in_class_rank'}),\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    if return_details:\n",
    "        return df_pred, df_y.sort_index()\n",
    "    else:\n",
    "        return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred, df_y_hist = norm_laplacian_lp(df_labels=df0, return_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=df_y_hist.loc[3324].index,\n",
    "        y=df_y_hist.loc[idx[3324, :], l],\n",
    "        name=l\n",
    "    )\n",
    "    for l in df_y_hist.columns\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=df_y_hist.loc[3311].index,\n",
    "        y=df_y_hist.loc[idx[3311, :], l],\n",
    "        name=l\n",
    "    )\n",
    "    for l in df_y_hist.columns\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=df_y_hist.loc[703].index,\n",
    "        y=df_y_hist.loc[idx[703, :], l],\n",
    "        name=l\n",
    "    )\n",
    "    for l in df_y_hist.columns\n",
    "]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how did this do against validation and training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, df_y_comparable, df_y_crosstab = prediction_evaluation(df_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[\n",
    "    go.Heatmap(\n",
    "        x=df_y_crosstab.index,\n",
    "        y=df_y_crosstab.columns,\n",
    "        z=df_y_crosstab.values,\n",
    "        colorscale='Reds',\n",
    "    )\n",
    "]\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algo 3: nearest-seed\n",
    "\n",
    "this is a \"social diffusion\" (i.e. edge/traversal-focused) algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_nearest_seed(df_labels, adj=adj):\n",
    "    # initialize\n",
    "    G = nx.DiGraph(adj)\n",
    "\n",
    "    # add the known labels\n",
    "    for (node_index, rec) in df_labels[df_labels.is_seed].iterrows():\n",
    "        G.node[node_index]['label'] = rec.label\n",
    "\n",
    "    # a counter of the number of times a nearest neighbor had a particular label\n",
    "    #df_c = df_labels.copy()\n",
    "    #df_c.loc[train_mask, 'count_val'] = 1\n",
    "\n",
    "    #df_c = df_c.pivot(\n",
    "    #    index=None,\n",
    "    #    columns='label',\n",
    "    #    values='count_val'\n",
    "    #).drop(columns=np.nan).fillna(0)\n",
    "    #df_c.head()\n",
    "    \n",
    "    # count is easier to build in the algo itself for now\n",
    "    df_c = pd.DataFrame()\n",
    "    \n",
    "    # seed predictions are constant, let's not belabor this\n",
    "    # known seeds get re-introduced with a value of 1\n",
    "    seeds = df_labels[df_labels.is_seed].index.values\n",
    "    df_seed_pred = pd.DataFrame(\n",
    "        data={\n",
    "            'label': df_labels.loc[seeds, 'label'],\n",
    "            'val': 1,\n",
    "            'is_seed': True\n",
    "        },\n",
    "        index=seeds\n",
    "    )\n",
    "    df_seed_pred.index.name = 'trg'\n",
    "    df_seed_pred.head()\n",
    "\n",
    "    return G, df_c, seeds, df_seed_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_edge_weights(G, delta=.5):\n",
    "    # randomly sample edge weights\n",
    "    for u in G:\n",
    "        # degree is both *out* and *in*\n",
    "        deg = G.degree(u) / 2\n",
    "\n",
    "        # DELTA rescaled by beta; larger degrees yield larger weights, etc\n",
    "        for v in G[u]:\n",
    "            G[u][v]['weight'] = np.random.exponential(deg) + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_seed(df_labels, n=100, delta=.5, adj=adj, rng_seed=1337, cutoff=20,\n",
    "                 return_details=False):\n",
    "    \"\"\"simple social diffusion model\n",
    "    \n",
    "    args:\n",
    "        df_labels (pd.DataFrame): a dataframe which contains three features:\n",
    "            `node_index`, a unique identifier for each node; `is_seed`, a \n",
    "            boolean indicating whether or not that particular node should be\n",
    "            considered a seed for this run of the algorithm, and `label`, an\n",
    "            integer value indicating which label that node has (should only be\n",
    "            set for seed nodes, but this is not enforced)\n",
    "        n (int): number of iterations to take (default: 100)\n",
    "        delta (float): hyperparameter setting a constant offset in the\n",
    "            exponential distribution sampling for edge weights (think of this as\n",
    "            a default minimum weight). (default: 0.5)\n",
    "        adj (np.NdArray): adjacency matrix of the graph\n",
    "        rng_seed (int): seed for the numpy random number generator\n",
    "        cutoff (float): cutoff ofr the dijkstra shortest path algorithm (don't\n",
    "            calculate any shortest paths longer than this number) (defaul: 20) \n",
    "        return_details (bool): whether or not to include the history of label \n",
    "            prediction values (default: False)\n",
    "    \n",
    "    returns:\n",
    "        pd.DataFrame: an augmented form of the input which provides predictions\n",
    "            for the unlabelled non-seed nodes as well as in-class ordering for\n",
    "            the confidence level of that prediction\n",
    "        pd.DataFrame (optional): prediction history of values over the number of\n",
    "            iterations (only returned if `return_details = True`)\n",
    "    \n",
    "    raises:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    np.random.seed(rng_seed)\n",
    "    \n",
    "    G, df_c, seeds, df_seed_pred = _init_nearest_seed(df_labels, adj)\n",
    "    \n",
    "    idx = pd.IndexSlice\n",
    "    \n",
    "    for i in tqdm.tnrange(n, leave=False):\n",
    "        _sample_edge_weights(G)\n",
    "        \n",
    "        # collect the closest labelled (seed) node for every unlabelled node\n",
    "        df_dists = pd.DataFrame()\n",
    "        for u in tqdm.tqdm_notebook(seeds, leave=False):\n",
    "            # find all distances from this seed to all nodes\n",
    "            dists = nx.single_source_dijkstra_path_length(\n",
    "                G, u, cutoff=cutoff, weight='weight'\n",
    "            )\n",
    "\n",
    "            df_dists_now = pd.DataFrame([\n",
    "                {\n",
    "                    'src': u, 'src_lab': G.node[u]['label'], 'trg': trg, \n",
    "                    'dist': dist\n",
    "                }\n",
    "                for (trg, dist) in dists.items()\n",
    "                if trg >= 120\n",
    "            ])\n",
    "\n",
    "            df_dists = df_dists.append(df_dists_now, ignore_index=True)\n",
    "\n",
    "        closest_labels = df_dists.sort_values(by=['trg', 'dist']) \\\n",
    "                                 .groupby('trg') \\\n",
    "                                 .first() \\\n",
    "                                 .reset_index()[['trg', 'src_lab']]\n",
    "\n",
    "        # our iter is actually easier if we just collect the closest labels for\n",
    "        # all increment the created counter with the nearest label\n",
    "        df_c = df_c.append(closest_labels, ignore_index=True).reset_index(drop=True)\n",
    "    \n",
    "    df_y_final = pd.crosstab(index=df_c.trg, columns=df_c.src_lab)\n",
    "    df_y_final = df_y_final.div(df_y_final.sum(axis=1), axis=0)\n",
    "\n",
    "    # pick out the final label value for each\n",
    "    df_pred = pd.DataFrame(\n",
    "        data={\n",
    "            'label': df_y_final.idxmax(axis=1),\n",
    "            'val': df_y_final.max(axis=1),\n",
    "        },\n",
    "        index=df_y_final.index\n",
    "    )\n",
    "\n",
    "    # join in the original is_seed values to calculate prediction ranking in-class\n",
    "    df_pred = df_pred.join(\n",
    "        df_labels.set_index('node_index').is_seed, \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # join in the constant seed values\n",
    "    df_pred = df_pred.append(df_seed_pred).sort_index()\n",
    "\n",
    "    # in-class ranking calculation\n",
    "    df_pred = df_pred.join(\n",
    "        df_pred.groupby(['is_seed', 'label']) \\\n",
    "            .rank(ascending=False, method='min') \\\n",
    "            .rename(columns={'val': 'in_class_rank'}),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    if return_details:\n",
    "        return df_pred, df_y_final.sort_index()\n",
    "    else:\n",
    "        return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred, df_y_final = nearest_seed(df_labels=df0, return_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how did this do against validation and training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, df_y_comparable, df_y_crosstab = prediction_evaluation(df_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[\n",
    "    go.Heatmap(\n",
    "        x=df_y_crosstab.index,\n",
    "        y=df_y_crosstab.columns,\n",
    "        z=df_y_crosstab.values,\n",
    "        colorscale='Reds',\n",
    "    )\n",
    "]\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bootstrapping wrapper\n",
    "\n",
    "now we implement a meta-algorithm / wrapper for bootstrapping the above three algorithms. we will effectively pull out some proportion of the best predictions for each of the above algorithms and treat them as new synthetic \"true\" labels. this process will be iterated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(df0, algo, n=100, r=.01, return_bootstrap_details=False, \n",
    "              return_algo_details=False, **kwargs):\n",
    "    \"\"\"the bootstrap wrapper for synthetic target propagation\n",
    "    \n",
    "    args:\n",
    "        df0 (pd.DataFrame): the initial dataframe containing seed information\n",
    "        algo (func): an algorithm function which will return label predictions\n",
    "            with a ranking feature\n",
    "        n (int): number of iterations for the algorithm (default: 100)\n",
    "        r (float): hyperparameter determining what fraciton of all the \n",
    "            unlabelled cases are converted into synthetic labels in teh \n",
    "            following iteration. note: must be between 0 and 1 (default: 0.01)\n",
    "        return_bootstrap_details (bool): whether or not to include the history\n",
    "            of predicted values obtained during successive iterations of the \n",
    "            bootstrap wrapper (default: False)\n",
    "        return_algo_details (bool): whether or not to include the history of the\n",
    "            algorithm's internal prediction values (default: False)\n",
    "        kwargs: will be pass directly to `algo`\n",
    "        \n",
    "    returns:\n",
    "        tbd\n",
    "        \n",
    "    raises:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not (0 < r < 1):\n",
    "        raise ValueError(\"r must be between 0 and 1\")\n",
    "        \n",
    "    df_labels = df0.copy()\n",
    "    df_pred = pd.DataFrame()\n",
    "    \n",
    "    # it is unclear in the paper whether the frequencies we use to balance class\n",
    "    # labels are meant to update as the populations change, but the basic\n",
    "    # pseudo-code for the algorithm leads me to beleive they are not. for now we\n",
    "    # will calculate them once and for all\n",
    "    # but the results blow ass if we do it this way so no\n",
    "    #freq = df_labels[df_labels.is_seed].label.value_counts(normalize=True)\n",
    "    \n",
    "    for i in tqdm.tnrange(n):\n",
    "        # make our predictions and record them as a history object\n",
    "        df_pred_now = algo(\n",
    "            df_labels, return_details=return_algo_details, **kwargs\n",
    "        )\n",
    "        df_pred_now.loc[:, 'bootstrap_iteration'] = i\n",
    "        df_pred_now.set_index('bootstrap_iteration', append=True, inplace=True)\n",
    "        df_pred = df_pred.append(df_pred_now, ignore_index=False)\n",
    "        \n",
    "        # update df_labels\n",
    "        candidates = df_pred_now[~df_pred_now.is_seed].copy().reset_index()\n",
    "\n",
    "        # moved frequency calculation here to be dependent on number of \n",
    "        # predicted labels\n",
    "        freq = candidates.label.value_counts()\n",
    "        \n",
    "        num_to_keep = pd.concat(\n",
    "            [\n",
    "                # frequency values\n",
    "                (r * freq).sort_index(),\n",
    "                # number available based on new predictions\n",
    "                candidates.label.value_counts().sort_index()\n",
    "            ],\n",
    "            axis=1\n",
    "        ).min(axis=1).astype(int).reset_index()\n",
    "        num_to_keep.columns = ['label', 'num_to_keep']\n",
    "        \n",
    "        # if we don't grow the size of our set at all, break\n",
    "        if num_to_keep.num_to_keep.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # go and get the top that-many from each group\n",
    "        candidates = candidates.merge(\n",
    "            num_to_keep,\n",
    "            how='left',\n",
    "            on='label',\n",
    "        )\n",
    "        candidates = candidates[\n",
    "            candidates.in_class_rank <= candidates.num_to_keep\n",
    "        ]\n",
    "        \n",
    "        # update df_labels with this new information\n",
    "        df_labels.loc[candidates.node_index, 'is_seed'] = True\n",
    "        df_labels.loc[candidates.node_index, 'label'] = candidates.label.values\n",
    "        df_labels.loc[candidates.node_index, 'is_synthetic'] = True\n",
    "        df_labels.loc[candidates.node_index, 'added_in_bootstrap_iteration'] = i\n",
    "    \n",
    "    if return_bootstrap_details:\n",
    "        return df_labels, df_pred\n",
    "    else:\n",
    "        return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels, df_pred = bootstrap(\n",
    "    df0, label_prop, n=20, r=0.1, return_bootstrap_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies, crosstabs = {}, {}\n",
    "for i in df_pred.index.get_level_values('bootstrap_iteration').unique():\n",
    "    accuracy, df_y_comparable, df_y_crosstab = prediction_evaluation(\n",
    "        df_pred.loc[idx[:, i], :]\n",
    "    )\n",
    "    accuracies[i] = accuracy\n",
    "    crosstabs[i] = df_y_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(i):\n",
    "    df_y_crosstab = crosstabs[i]\n",
    "    data =[\n",
    "        go.Heatmap(\n",
    "            x=df_y_crosstab.index,\n",
    "            y=df_y_crosstab.columns,\n",
    "            z=df_y_crosstab.values,\n",
    "            colorscale='Reds',\n",
    "        )\n",
    "    ]\n",
    "    plotly.offline.iplot(data)\n",
    "\n",
    "interact(f, i=widgets.IntSlider(min=0, max=max(crosstabs.keys()), step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
